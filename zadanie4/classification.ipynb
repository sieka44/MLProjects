{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "DONE",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Please train the network on the data from file classification_problem.npy. File can be loaded using np.load() function. It contains 3000 rows. First 1000 rows coressponds to class 0, next 1000 to class1 and last 1000 rows to class 2.#%%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Data reshaped",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "size = 3000\n",
    "data = np.load('classification_problem.npy')\n",
    "data_reshape =  np.hstack((data,np.zeros((data.shape[0],1))))\n",
    "for dd in range(size):\n",
    "    data_reshape[dd] = np.append(data[dd],[np.long(dd/1000)+1])\n",
    "print(\"Data reshaped\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(3000, 13)",
      "\n",
      "torch.Size([3000, 12])",
      "\n",
      "torch.Size([3000, 1])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train = torch.from_numpy(data)\n",
    "y_train = torch.from_numpy(data_reshape[:,12:13])\n",
    "print(data_reshape.shape)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model created",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "n_in = 12\n",
    "n_hidden = 128\n",
    "n_out = 4\n",
    "training_model = \\\n",
    "    torch.nn.Sequential(torch.nn.Linear(n_in,n_hidden,bias=True),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(n_hidden,n_out),\n",
    "                        torch.nn.LogSoftmax(dim=1))\n",
    "print(\"Model created\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "200",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "valid_size = 200\n",
    "dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "(train_set, valid_set) = torch.utils.data.random_split(dataset,(size-valid_size,valid_size))\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=valid_size,shuffle=True)\n",
    "print(valid_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "epoch 0 1.098546 1.099597 ",
      "\n",
      "epoch 100 1.098482 1.098944 ",
      "\n",
      "epoch 200 1.099067 1.098940 ",
      "\n",
      "epoch 300 1.098697 1.098837 ",
      "\n",
      "epoch 400 1.098772 1.098894 ",
      "\n",
      "epoch 500 1.098494 1.098950 ",
      "\n",
      "epoch 600 1.098379 1.098840 ",
      "\n",
      "epoch 700 1.098804 1.098975 ",
      "\n",
      "epoch 800 1.098407 1.098878 ",
      "\n",
      "epoch 900 1.098861 1.098917 ",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(training_model.parameters(),lr =0.001)\n",
    "loss_func = torch.nn.NLLLoss()\n",
    "max_epoch = 1000\n",
    "loss = 0\n",
    "err_train=[]\n",
    "err_valid=[]\n",
    "valid_data = Variable(valid_set[:][0],requires_grad=False)\n",
    "valid_target = Variable(valid_set[:][1].long(),requires_grad=False)\n",
    "for epoch in range(max_epoch):\n",
    "    for datum in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        (features,target1) = datum\n",
    "        data = Variable(features,requires_grad=False)\n",
    "        target = Variable(target1.long(),requires_grad=False)\n",
    "        pred = training_model(features)\n",
    "        loss = loss_func(pred, target.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            vpred  = training_model(valid_data)\n",
    "            vloss  = loss_func(vpred,valid_target.view(-1))\n",
    "            err_valid.append(vloss)\n",
    "            pred  = training_model(data)\n",
    "            loss  = loss_func(pred,target.view(-1))\n",
    "            err_train.append(loss)\n",
    "    if epoch%100 == 0:\n",
    "        print(\"epoch %d %f %f \" % (epoch, loss, vloss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}